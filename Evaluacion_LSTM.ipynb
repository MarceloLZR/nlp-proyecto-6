{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369d552c",
   "metadata": {},
   "source": [
    "# üìä Evaluaci√≥n rigurosa de modelos RNN: Perplejidad y palabras fuera de vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889768b",
   "metadata": {},
   "source": [
    "Este notebook presenta una implementaci√≥n estructurada para evaluar modelos LSTM en tareas de modelado de lenguaje, \n",
    "haciendo especial √©nfasis en m√©tricas como la *Perplejidad* (PP) y el manejo de palabras fuera de vocabulario (*Out-Of-Vocabulary*, OOV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3f22a",
   "metadata": {},
   "source": [
    "## üîß BLOQUE 1: Setup y descarga de datos\n",
    "\n",
    "- Instalaci√≥n de dependencias necesarias (`torch`, `torchtext`, `nltk`, etc.).\n",
    "- Descarga del dataset **WikiText-2**.\n",
    "- Tokenizaci√≥n del corpus.\n",
    "- Construcci√≥n de vocabulario con diferentes tama√±os:\n",
    "  - 10,000 palabras\n",
    "  - 30,000 palabras\n",
    "  - 50,000 palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc73ae0",
   "metadata": {},
   "source": [
    "# üîß Bloque 1: Setup y descarga de datos\n",
    "\n",
    "### üìö Teor√≠a\n",
    "El dataset **WikiText-2** es un corpus ampliamente utilizado para tareas de modelado de lenguaje. Contiene texto derivado de art√≠culos de Wikipedia y es √∫til para entrenar y evaluar modelos de predicci√≥n de texto.\n",
    "\n",
    "Antes de entrenar cualquier modelo, es importante:\n",
    "1. Descargar el corpus.\n",
    "2. Tokenizar el texto.\n",
    "3. Construir un vocabulario de tama√±o controlado (ej. 10^4, 3x10^4, 5x10^4 tokens).\n",
    "4. Dividir en datasets de entrenamiento, validaci√≥n y prueba.\n",
    "\n",
    "Utilizaremos `torchtext`, que facilita todo este proceso con utilidades listas para usar.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2059da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.18.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext) (4.66.5)\n",
      "Requirement already satisfied: requests in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext) (2.32.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchtext) (1.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchtext) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\marcelo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Downloading torchtext-0.18.0-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instalaci√≥n de dependencias necesarias (si no est√°n disponibles)\n",
    "!pip install torch torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b95ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcelo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchtext\\__init__.py:7: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\\n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \\n\"\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WikiText2\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n",
      "File \u001b[1;32mc:\\Users\\Marcelo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchtext\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Marcelo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Marcelo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[1;32mc:\\Users\\Marcelo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marcelo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_ops.py:1295\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1290\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m-> 1295\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32mc:\\Users\\Marcelo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ctypes\\__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "# Selecci√≥n de tokenizer tipo 'basic_english'\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# Carga de datasets\n",
    "train_iter = WikiText2(split='train')\n",
    "valid_iter = WikiText2(split='valid')\n",
    "test_iter = WikiText2(split='test')\n",
    "\n",
    "# Tokenizaci√≥n y conteo de frecuencias\n",
    "counter = Counter()\n",
    "for line in train_iter:\n",
    "    counter.update(tokenizer(line))\n",
    "\n",
    "# Ejemplo: Crear vocabulario de tama√±o 10^4\n",
    "vocab_size = 10_000\n",
    "vocab = Vocab(counter, max_size=vocab_size, specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78dcd3",
   "metadata": {},
   "source": [
    "## üß† BLOQUE 2: Definici√≥n del modelo\n",
    "\n",
    "Se define un modelo LSTM con las siguientes caracter√≠sticas:\n",
    "\n",
    "- Embeddings de dimensi√≥n 300.\n",
    "- Dos capas LSTM con tama√±o oculto de 512.\n",
    "- Capa final densa con softmax para predecir la siguiente palabra.\n",
    "\n",
    "**Componentes del modelo:**\n",
    "- `Embedding layer`\n",
    "- `LSTM layers (stacked)`\n",
    "- `Linear output layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218eb4d",
   "metadata": {},
   "source": [
    "## üèãÔ∏è BLOQUE 3: Entrenamiento\n",
    "\n",
    "Entrenamos tres versiones del modelo, una por cada tama√±o de vocabulario.\n",
    "\n",
    "**Funciones incluidas:**\n",
    "- Entrenamiento y validaci√≥n por √©pocas.\n",
    "- Registro de m√©tricas:\n",
    "  - *Perplejidad* sobre conjunto de validaci√≥n.\n",
    "  - Conteo y porcentaje de palabras OOV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26eed21",
   "metadata": {},
   "source": [
    "## üß© BLOQUE 4: Manejo de OOV\n",
    "\n",
    "Se comparan tres estrategias de tratamiento para palabras fuera de vocabulario:\n",
    "\n",
    "1. **Token `<UNK>`:** se reemplazan todas las palabras desconocidas por un token especial.\n",
    "2. **Modelo char-level:** backoff a un modelo de caracteres para predecir embeddings.\n",
    "3. **Similitud de Levenshtein:** reemplazo por la palabra m√°s cercana en el vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080a96c",
   "metadata": {},
   "source": [
    "## üìà BLOQUE 5: Evaluaci√≥n\n",
    "\n",
    "M√©tricas medidas:\n",
    "\n",
    "- **Perplejidad** en el conjunto de prueba.\n",
    "- **Porcentaje de OOV** en test.\n",
    "- Comparaci√≥n entre modelos con distintos vocabularios y estrategias OOV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73427393",
   "metadata": {},
   "source": [
    "## üìä BLOQUE 6: An√°lisis y visualizaci√≥n\n",
    "\n",
    "Incluye:\n",
    "\n",
    "- Gr√°ficos de perplejidad vs. tama√±o de vocabulario.\n",
    "- Cobertura del vocabulario vs. porcentaje de OOV.\n",
    "- Comparativa de estrategias de manejo de OOV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558dc0eb",
   "metadata": {},
   "source": [
    "## üìò BLOQUE 7: Reporte final\n",
    "\n",
    "Resumen de hallazgos:\n",
    "\n",
    "- Impacto del tama√±o del vocabulario sobre la perplejidad.\n",
    "- Eficacia relativa de cada estrategia de OOV.\n",
    "- Recomendaciones para aplicaciones en producci√≥n.\n",
    "\n",
    "**Exportable a PDF o documento acad√©mico.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
